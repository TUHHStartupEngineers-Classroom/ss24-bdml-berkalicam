---
title: "05 Explaining Black-Box Models With LIME"
author: "Berk Ali Cam"
date: "2024-06-25"

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```


```{r}
# LIME FEATURE EXPLANATION ----

# 1. Setup ----

# Load Libraries 
library(tidymodels)
library(magrittr)
library(dplyr)
library(sjmisc)
library(magrittr)
library(haven)
library(sjlabelled)
library(rsample)
library(recipes)
library(rstanarm)
library(broom.mixed)
library(h2o)
library(readxl)
library(tidyverse)
library(tidyquant)
library(lime)
```

```{r}

# Load Data
employee_attrition_tbl <- read_csv("raw_data/datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv")
definitions_raw_tbl    <- read_excel("raw_data/data_definitions.xlsx", sheet = 1, col_names = FALSE)

# Processing Pipeline
source("00_Scripts/data_processing_pipeline.R")

employee_attrition_readable_tbl <- process_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl)

# Split into test and train
set.seed(seed = 1113)
split_obj <- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)

# Assign training and test data
train_readable_tbl <- training(split_obj)
test_readable_tbl  <- testing(split_obj)

# ML Preprocessing Recipe 
recipe_obj <- recipe(Attrition ~ ., data = train_readable_tbl) %>%
  step_zv(all_predictors()) %>%
  step_mutate_at(c("JobLevel", "StockOptionLevel"), fn = as.factor) %>% 
  prep()

recipe_obj

train_tbl <- bake(recipe_obj, new_data = train_readable_tbl)
test_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)

```

```{r}


# 2. Models ----

h2o.init()
h2o.getModel("metalearner_AUTO_StackedEnsemble_AllModels_1_AutoML_9_20220524_185544") %>% 
h2o.saveModel(path = "h20_models/")

automl_leader <- h2o.loadModel("h20_models/StackedEnsemble_BestOfFamily_1_AutoML")

automl_leader <- h2o.loadModel("h20_models/StackedEnsemble_AllModels_3_AutoML_1_20230612_154953 - Copy")


```

```{r}

# 3. LIME ----

# 3.1 Making Predictions ----

 predictions_tbl <- automl_leader %>% 
     h2o.predict(newdata = as.h2o(test_tbl)) %>%
     as.tibble() %>%
     bind_cols(
         test_tbl %>%
           select(EducationField)
     )
 
 predictions_tbl
 test_tbl %>%
   slice(1) %>%
   glimpse()

## 3.2 Single Explanation ----

explainer <- train_tbl %>%
   select(-Attrition) %>%
   lime(
    model           = automl_leader,
    bin_continuous  = TRUE,
    n_bins          = 4,
    quantile_bins   = TRUE
  )



?lime::explain
 
 explanation <- test_tbl %>%
   slice(1) %>%
   select(-Attrition) %>%
 lime::explain(
     explainer = explainer,
     n_labels   = 1,
     n_features = 8,
     n_permutations = 5000,
     kernel_width   = 1
   )
 
## explanation
 
 explanation %>%
   as.tibble() %>%
   select(feature:prediction) 
 
 g <- plot_features(explanation = explanation, ncol = 1)
 
 plot_features(explanation = explanation, ncol = 1)
 
# # 3.3 Multiple Explanations ----
 
 explanation <- test_tbl %>%
   slice(1:20) %>%
   select(-Attrition) %>%
   lime::explain(
     explainer = explainer,
     n_labels   = 1,
     n_features = 8,
     n_permutations = 5000,
     kernel_width   = 0.5
   )
 
 explanation %>%
   as.tibble()
 
 plot_features(explanation, ncol = 4)
 
 plot_explanations(explanation)
# # Challenge part 1 ----
 explanation %>% 
   as.tibble()
 
 case_1 <- explanation %>%
   filter(case == 1)
 
 case_1 %>%
   plot_features()
 
 case_1 %>%
   ggplot(aes(feature_weight, feature)) +
   geom_col(fill = "#1a2c50") +
   geom_smooth(method = "lm", se = FALSE) +
   scale_fill_manual(values = c("steelblue", "firebrick"), drop = FALSE) +
   labs(
     title = ("Model explanation"),
     x = "Weight",
     y = "Feature"
  ) +
   theme_tq_dark()
 


```