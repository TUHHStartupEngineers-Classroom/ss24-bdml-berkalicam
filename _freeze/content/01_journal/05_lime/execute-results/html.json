{
  "hash": "8009d0342b4c45c9a145912c548d9aeb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"05 Explaining Black-Box Models With LIME\"\nauthor: \"Berk Ali Cam\"\ndate: \"2024-06-25\"\n\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# LIME FEATURE EXPLANATION ----\n\n# 1. Setup ----\n\n# Load Libraries \nlibrary(tidymodels)\nlibrary(magrittr)\nlibrary(dplyr)\nlibrary(sjmisc)\nlibrary(magrittr)\nlibrary(haven)\nlibrary(sjlabelled)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(rstanarm)\nlibrary(broom.mixed)\nlibrary(h2o)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(lime)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load Data\nemployee_attrition_tbl <- read_csv(\"raw_data/datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Rows: 1470 Columns: 35\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\n#> dbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ndefinitions_raw_tbl    <- read_excel(\"raw_data/data_definitions.xlsx\", sheet = 1, col_names = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> New names:\n#> • `` -> `...1`\n#> • `` -> `...2`\n```\n\n\n:::\n\n```{.r .cell-code}\n# Processing Pipeline\nsource(\"00_Scripts/data_processing_pipeline.R\")\n\nemployee_attrition_readable_tbl <- process_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Joining with `by = join_by(Education)`\n#> Joining with `by = join_by(EnvironmentSatisfaction)`\n#> Joining with `by = join_by(JobInvolvement)`\n#> Joining with `by = join_by(JobSatisfaction)`\n#> Joining with `by = join_by(PerformanceRating)`\n#> Joining with `by = join_by(RelationshipSatisfaction)`\n#> Joining with `by = join_by(WorkLifeBalance)`\n```\n\n\n:::\n\n```{.r .cell-code}\n# Split into test and train\nset.seed(seed = 1113)\nsplit_obj <- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)\n\n# Assign training and test data\ntrain_readable_tbl <- training(split_obj)\ntest_readable_tbl  <- testing(split_obj)\n\n# ML Preprocessing Recipe \nrecipe_obj <- recipe(Attrition ~ ., data = train_readable_tbl) %>%\n  step_zv(all_predictors()) %>%\n  step_mutate_at(c(\"JobLevel\", \"StockOptionLevel\"), fn = as.factor) %>% \n  prep()\n\nrecipe_obj\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> \n#> ── Recipe ──────────────────────────────────────────────────────────────────────\n#> \n#> ── Inputs \n#> Number of variables by role\n#> outcome:    1\n#> predictor: 34\n#> \n#> ── Training information \n#> Training data contained 1249 data points and no incomplete rows.\n#> \n#> ── Operations \n#> • Zero variance filter removed: EmployeeCount and Over18, ... | Trained\n#> • Variable mutation for: JobLevel and StockOptionLevel | Trained\n```\n\n\n:::\n\n```{.r .cell-code}\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2. Models ----\n\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> H2O is not running yet, starting it now...\n#> \n#> Note:  In case of errors look at the following log files:\n#>     C:\\Users\\BERKCA~1\\AppData\\Local\\Temp\\RtmpQVW2aE\\file381c79152a96/h2o_Berk_Cam_started_from_r.out\n#>     C:\\Users\\BERKCA~1\\AppData\\Local\\Temp\\RtmpQVW2aE\\file381ce0a24f5/h2o_Berk_Cam_started_from_r.err\n#> \n#> \n#> Starting H2O JVM and connecting:  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         3 seconds 662 milliseconds \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 year, 1 month and 27 days \n#>     H2O cluster name:           H2O_started_from_R_Berk_Cam_drs368 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   7.67 GB \n#>     H2O cluster total cores:    16 \n#>     H2O cluster allowed cores:  16 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.4.1 (2024-06-14 ucrt)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning in h2o.clusterInfo(): \n#> Your H2O cluster version is (1 year, 1 month and 27 days) old. There may be a newer version available.\n#> Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n```\n\n\n:::\n\n```{.r .cell-code}\n#h2o.getModel(\"metalearner_AUTO_StackedEnsemble_AllModels_1_AutoML_9_20220524_185544\") %>% \n#  h2o.saveModel(path = \"h20_models/\")\n\n#automl_leader <- h2o.loadModel(\"h20_models/StackedEnsemble_BestOfFamily_1_AutoML\")\n\n#automl_leader <- h2o.loadModel(\"h20_models/StackedEnsemble_AllModels_3_AutoML_1_20230612_154953 - Copy\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 3. LIME ----\n\n# 3.1 Making Predictions ----\n\n# predictions_tbl <- automl_leader %>% \n#     h2o.predict(newdata = as.h2o(test_tbl)) %>%\n#     as.tibble() %>%\n#     bind_cols(\n#         test_tbl %>%\n#             select(EducationField)\n#     )\n# \n# predictions_tbl\n# test_tbl %>%\n#   slice(1) %>%\n#   glimpse()\n# \n## 3.2 Single Explanation ----\n# \n# explainer <- train_tbl %>%\n#   select(-Attrition) %>%\n#   lime(\n#     model           = automl_leader,\n#     bin_continuous  = TRUE,\n#     n_bins          = 4,\n#     quantile_bins   = TRUE\n#   )\n# \n# explainer\n# \n# ?lime::explain\n# \n# explanation <- test_tbl %>%\n#   slice(1) %>%\n#   select(-Attrition) %>%\n#   lime::explain(\n#     \n#     # Pass our explainer object\n#     explainer = explainer,\n#     # Because it is a binary classification model: 1\n#     n_labels   = 1,\n#     # number of features to be returned\n#     n_features = 8,\n#     # number of localized linear models\n#     n_permutations = 5000,\n#     # Let's start with 1\n#     kernel_width   = 1\n#   )\n# \n## explanation\n# \n# explanation %>%\n#   as.tibble() %>%\n#   select(feature:prediction) \n# \n# g <- plot_features(explanation = explanation, ncol = 1)\n# \n# plot_features(explanation = explanation, ncol = 1)\n# \n# # 3.3 Multiple Explanations ----\n# \n# explanation <- test_tbl %>%\n#   slice(1:20) %>%\n#   select(-Attrition) %>%\n#   lime::explain(\n#     explainer = explainer,\n#     n_labels   = 1,\n#     n_features = 8,\n#     n_permutations = 5000,\n#     kernel_width   = 0.5\n#   )\n# \n# explanation %>%\n#   as.tibble()\n# \n# plot_features(explanation, ncol = 4)\n# \n# plot_explanations(explanation)\n# # Challenge part 1 ----\n# explanation %>% \n#   as.tibble()\n# \n# case_1 <- explanation %>%\n#   filter(case == 1)\n# \n# case_1 %>%\n#   plot_features()\n# \n# case_1 %>%\n#   ggplot(aes(feature_weight, feature)) +\n#   geom_col(fill = \"#1a2c50\") +\n#   geom_smooth(method = \"lm\", se = FALSE) +\n#   scale_fill_manual(values = c(\"steelblue\", \"firebrick\"), drop = FALSE) +\n#   labs(\n#     title = (\"Model explanation\"),\n#     x = \"Weight\",\n#     y = \"Feature\"\n#   ) +\n#   theme_tq_dark()\n# \n# # Challenge part 2 ----\n# explanation %>% ggplot(aes_(~case, ~feature_desc)) +\n#   geom_tile(aes_(fill = ~feature_weight)) + \n#   scale_x_discrete(\"Case\", expand = c(0, 0)) +\n#   scale_y_discrete(\"Feature\", expand = c(0, 0)) +\n#   scale_fill_gradient2(\"Feature\\nweight\", low = \"firebrick\", mid = \"#f7f7f7\", high = \"steelblue\") +\n#   theme(panel.border = element_rect(fill = NA,\n#                                     colour = \"grey60\",\n#                                     size = 1),\n#         panel.grid = element_blank(),\n#         legend.position = \"right\",\n#         axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +\n#   facet_wrap(~label)\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}